{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import OPTForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OPTForCausalLM.from_pretrained('facebook/opt-350m', torch_dtype='auto')\n",
    "model.eval()\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.model.decoder.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def find_layers(module, layers=[nn.Conv2d, nn.Linear], name=''):\n",
    "    if type(module) in layers:\n",
    "        return {name: module}\n",
    "    res = {}\n",
    "    for name1, child in module.named_children():\n",
    "        res.update(find_layers(\n",
    "            child, layers=layers, name=name + '.' + name1 if name != '' else name1\n",
    "        ))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers[0].to(device)\n",
    "subset = find_layers(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x, scale, zero, maxq):\n",
    "    if maxq < 0:\n",
    "        return (x > scale / 2).float() * scale + (x < zero / 2).float() * zero\n",
    "    q = torch.clamp(torch.round(x / scale) + zero, 0, maxq)\n",
    "    return scale * (q - zero)\n",
    "\n",
    "class RTN(nn.Module):\n",
    "\n",
    "    def __init__(self, shape=1):\n",
    "        super(RTN, self).__init__()\n",
    "        self.register_buffer('maxq', torch.tensor(0))\n",
    "        self.register_buffer('scale', torch.zeros(shape))\n",
    "        self.register_buffer('zero', torch.zeros(shape))\n",
    "\n",
    "    def configure(\n",
    "        self,\n",
    "        bits, perchannel=False, sym=True, \n",
    "        mse=False, norm=2.4, grid=100, maxshrink=.8,\n",
    "        trits=False\n",
    "    ):\n",
    "        self.maxq = torch.tensor(2 ** bits - 1)\n",
    "        self.perchannel = perchannel\n",
    "        self.sym = sym\n",
    "        self.mse = mse\n",
    "        self.norm = norm\n",
    "        self.grid = grid\n",
    "        self.maxshrink = maxshrink \n",
    "        if trits:\n",
    "            self.maxq = torch.tensor(-1) \n",
    "\n",
    "    def find_params(self, x, weight=False):\n",
    "        dev = x.device\n",
    "        self.maxq = self.maxq.to(dev)\n",
    "\n",
    "        shape = x.shape\n",
    "        if self.perchannel:\n",
    "            if weight:\n",
    "                x = x.flatten(1)\n",
    "            else:\n",
    "                if len(shape) == 4:\n",
    "                    x = x.permute([1, 0, 2, 3])\n",
    "                    x = x.flatten(1)\n",
    "                if len(shape) == 3:\n",
    "                    x = x.reshape((-1, shape[-1])).t()\n",
    "                if len(shape) == 2:\n",
    "                    x = x.t()\n",
    "        else:\n",
    "            x = x.flatten().unsqueeze(0)\n",
    "\n",
    "        tmp = torch.zeros(x.shape[0], device=dev)\n",
    "        xmin = torch.minimum(x.min(1)[0], tmp)\n",
    "        xmax = torch.maximum(x.max(1)[0], tmp)\n",
    "\n",
    "        if self.sym:\n",
    "            xmax = torch.maximum(torch.abs(xmin), xmax)\n",
    "            tmp = xmin < 0\n",
    "            if torch.any(tmp):\n",
    "                xmin[tmp] = -xmax[tmp]\n",
    "        tmp = (xmin == 0) & (xmax == 0)\n",
    "        xmin[tmp] = -1\n",
    "        xmax[tmp] = +1\n",
    "\n",
    "        if self.maxq < 0:\n",
    "          self.scale = xmax\n",
    "          self.zero = xmin\n",
    "        else:\n",
    "          self.scale = (xmax - xmin) / self.maxq\n",
    "          if self.sym:\n",
    "              self.zero = torch.full_like(self.scale, (self.maxq + 1) / 2)\n",
    "          else:\n",
    "              self.zero = torch.round(-xmin / self.scale)\n",
    "\n",
    "        if self.mse:\n",
    "            best = torch.full([x.shape[0]], float('inf'), device=dev)\n",
    "            for i in range(int(self.maxshrink * self.grid)):\n",
    "                p = 1 - i / self.grid \n",
    "                xmin1 = p * xmin\n",
    "                xmax1 = p * xmax\n",
    "                scale1 = (xmax1 - xmin1) / self.maxq\n",
    "                zero1 = torch.round(-xmin1 / scale1) if not self.sym else self.zero\n",
    "                q = quantize(x, scale1.unsqueeze(1), zero1.unsqueeze(1), self.maxq)\n",
    "                q -= x\n",
    "                q.abs_()\n",
    "                q.pow_(self.norm)\n",
    "                err = torch.sum(q, 1)\n",
    "                tmp = err < best\n",
    "                if torch.any(tmp):\n",
    "                    best[tmp] = err[tmp]\n",
    "                    self.scale[tmp] = scale1[tmp]\n",
    "                    self.zero[tmp] = zero1[tmp]\n",
    "        if not self.perchannel:\n",
    "            if weight:\n",
    "                tmp = shape[0]\n",
    "            else:\n",
    "                tmp = shape[1] if len(shape) != 3 else shape[2]\n",
    "            self.scale = self.scale.repeat(tmp)\n",
    "            self.zero = self.zero.repeat(tmp)\n",
    "\n",
    "        if weight:\n",
    "            shape = [-1] + [1] * (len(shape) - 1)\n",
    "            self.scale = self.scale.reshape(shape)\n",
    "            self.zero = self.zero.reshape(shape)\n",
    "            return\n",
    "        if len(shape) == 4:\n",
    "            self.scale = self.scale.reshape((1, -1, 1, 1))\n",
    "            self.zero = self.zero.reshape((1, -1, 1, 1))\n",
    "        if len(shape) == 3:\n",
    "            self.scale = self.scale.reshape((1, 1, -1))\n",
    "            self.zero = self.zero.reshape((1, 1, -1)) \n",
    "        if len(shape) == 2:\n",
    "            self.scale = self.scale.unsqueeze(0)\n",
    "            self.zero = self.zero.unsqueeze(0)\n",
    "\n",
    "    def quantize(self, x):\n",
    "        if self.ready():\n",
    "            return quantize(x, self.scale, self.zero, self.maxq)\n",
    "        return x\n",
    "\n",
    "    def enabled(self):\n",
    "        return self.maxq > 0\n",
    "\n",
    "    def ready(self):\n",
    "        return torch.all(self.scale != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = RTN()\n",
    "quantizer.configure(4, perchannel=True, sym=False, mse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer.maxq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'fc1': Linear(in_features=1024, out_features=4096, bias=True),\n",
       " 'fc2': Linear(in_features=4096, out_features=1024, bias=True)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = subset['fc2'].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 4096])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = W\n",
    "x = x.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 4096])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.zeros(x.shape[0], device=device)\n",
    "xmin = torch.minimum(x.min(1)[0], tmp)\n",
    "xmax = torch.maximum(x.max(1)[0], tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (xmin == 0) & (xmax == 0)\n",
    "xmin[tmp] = -1\n",
    "xmax[tmp] = +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = (xmax - xmin) / quantizer.maxq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = torch.round(-xmin / scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = scale.unsqueeze(0)\n",
    "zero = zero.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['fc2'].weight.data = quantize(x.t(), scale, zero, quantizer.maxq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q = quantize(x.t(), scale, zero, quantizer.maxq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_q.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(layer.parameters())).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1438, device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youpengzhao/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/youpengzhao/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    }
   ],
   "source": [
    "testdata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/opt-350m', use_fast=False)\n",
    "testloader = tokenizer(\"\\n\\n\".join(testdata['text']), return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 287645])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287645"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader['input_ids'].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2176"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer 1\n",
      "Quantizing layer 2\n",
      "Quantizing layer 3\n",
      "Quantizing layer 4\n",
      "Quantizing layer 5\n",
      "Quantizing layer 6\n",
      "Quantizing layer 7\n",
      "Quantizing layer 8\n",
      "Quantizing layer 9\n",
      "Quantizing layer 10\n",
      "Quantizing layer 11\n",
      "Quantizing layer 12\n",
      "Quantizing layer 13\n",
      "Quantizing layer 14\n",
      "Quantizing layer 15\n",
      "Quantizing layer 16\n",
      "Quantizing layer 17\n",
      "Quantizing layer 18\n",
      "Quantizing layer 19\n",
      "Quantizing layer 20\n",
      "Quantizing layer 21\n",
      "Quantizing layer 22\n",
      "Quantizing layer 23\n",
      "Quantizing layer 24\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(layers)):\n",
    "    print('Quantizing layer {}'.format(i))\n",
    "    layer = layers[i].to(device)\n",
    "    subset = find_layers(layer)\n",
    "    for name in subset:\n",
    "        quantizer = RTN()\n",
    "        quantizer.configure(\n",
    "            4, perchannel=True, sym=False, mse=False\n",
    "        )\n",
    "        W = subset[name].weight.data\n",
    "        quantizer.find_params(W, weight=True)\n",
    "        subset[name].weight.data = quantize(W, \n",
    "                                            quantizer.scale, quantizer.zero, quantizer.maxq\n",
    "                                            ).to(next(iter(layer.parameters())).dtype)\n",
    "    layers[i] = layer.cpu()\n",
    "    del layer\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.decoder.layers = layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'opt_350m_4_bit.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = testloader['input_ids'].numel() // 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.9375, device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for i in range(num_samples):\n",
    "        outputs = model(input_ids=testloader['input_ids'][:, (i * 2048):((i + 1) * 2048)].to(device), \n",
    "                        labels=testloader['input_ids'][:, (i * 2048):((i + 1) * 2048)].to(device),\n",
    "                        attention_mask = testloader[\"attention_mask\"][:, (i * 2048):((i + 1) * 2048)].to(device).to(device))\n",
    "        losses.append(outputs[0])\n",
    "    loss = torch.mean(torch.stack(losses))\n",
    "    perplexity = torch.exp(loss)\n",
    "\n",
    "print(perplexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OPTForCausalLM.from_pretrained('facebook/opt-350m', torch_dtype='auto')\n",
    "model.eval()\n",
    "device = torch.device('cuda:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.0156, device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for i in range(num_samples):\n",
    "        outputs = model(input_ids=testloader['input_ids'][:, (i * 2048):((i + 1) * 2048)].to(device), \n",
    "                        labels=testloader['input_ids'][:, (i * 2048):((i + 1) * 2048)].to(device),\n",
    "                        attention_mask = testloader[\"attention_mask\"][:, (i * 2048):((i + 1) * 2048)].to(device).to(device))\n",
    "        losses.append(outputs[0])\n",
    "    loss = torch.mean(torch.stack(losses))\n",
    "    perplexity = torch.exp(loss)\n",
    "\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained('facebook/opt-350m')\n",
    "model = OPTForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('opt_350m_4_bit.pt', map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29.4278, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for i in range(num_samples):\n",
    "        outputs = model(input_ids=testloader['input_ids'][:, (i * 2048):((i + 1) * 2048)].to(device), \n",
    "                        labels=testloader['input_ids'][:, (i * 2048):((i + 1) * 2048)].to(device),\n",
    "                        attention_mask = testloader[\"attention_mask\"][:, (i * 2048):((i + 1) * 2048)].to(device).to(device))\n",
    "        losses.append(outputs[0])\n",
    "    loss = torch.mean(torch.stack(losses))\n",
    "    perplexity = torch.exp(loss)\n",
    "\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL: 29.43\n"
     ]
    }
   ],
   "source": [
    "print('PPL: {:.2f}'.format(perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youpengzhao/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 693/693 [00:00<00:00, 101kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.12G/1.12G [00:21<00:00, 52.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BloomForCausalLM\n",
    "model = BloomForCausalLM.from_pretrained('bigscience/bloom-560M', torch_dtype='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.transformer.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import OPTForCausalLM\n",
    "\n",
    "model = OPTForCausalLM.from_pretrained('facebook/opt-350m', torch_dtype='auto')\n",
    "model.eval()\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.model.decoder.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "def find_layers(module, layers=[nn.Conv2d, nn.Linear], name=''):\n",
    "    if type(module) in layers:\n",
    "        return {name: module}\n",
    "    res = {}\n",
    "    for name1, child in module.named_children():\n",
    "        res.update(find_layers(\n",
    "            child, layers=layers, name=name + '.' + name1 if name != '' else name1\n",
    "        ))\n",
    "    return res\n",
    "\n",
    "layer = layers[0].to(device)\n",
    "subset = find_layers(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'fc1': Linear(in_features=1024, out_features=4096, bias=True),\n",
       " 'fc2': Linear(in_features=4096, out_features=1024, bias=True)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantization.gptq import GPTQ\n",
    "\n",
    "name = 'fc2'\n",
    "gptq = {}\n",
    "gptq[name] = GPTQ(subset[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantization.rtn import RTN\n",
    "\n",
    "gptq[name].quantizer = RTN()\n",
    "gptq[name].quantizer.configure(\n",
    "                4, perchannel=True, sym=False, mse=False, trits=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = next(iter(model.parameters())).dtype\n",
    "inps = torch.zeros(\n",
    "        (128, 2048, model.config.hidden_size), dtype=dtype, device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {'i': 0, 'attention_mask': None}\n",
    "\n",
    "class Catcher(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "    def forward(self, inp, **kwargs):\n",
    "        inps[cache['i']] = inp\n",
    "        cache['i'] += 1\n",
    "        cache['attention_mask'] = kwargs['attention_mask']\n",
    "        raise ValueError\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[0] = Catcher(layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/youpengzhao/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    }
   ],
   "source": [
    "from data import get_sample_data\n",
    "\n",
    "trainloader = get_sample_data('wikitext2', 'facebook/opt-350m', 128, 2048)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in trainloader:\n",
    "    try:\n",
    "        model(batch[0].to(device))\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6225, 1003,    7,  ...,  645,    7, 5709]]),\n",
       " tensor([[-100, -100, -100,  ..., -100, -100, 5709]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[0] = layers[0].module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTDecoderLayer(\n",
       "  (self_attn): OPTAttention(\n",
       "    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (activation_fn): ReLU()\n",
       "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 0, 'attention_mask': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = torch.zeros_like(inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_batch(name):\n",
    "    def tmp(_, inp, out):\n",
    "        gptq[name].add_batch(inp[0].data, out.data)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
